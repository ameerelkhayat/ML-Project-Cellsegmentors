# Yeast Cell Segmentation with Generalist Deep Neural Network Mediar-Former 

**Group members:** Yanruiqi Yang(#346510), Yasmine Chaker(#311675), Ameer Elkhayat(#303778)

## Data preparation:

1. Training Dataset:
   906 yeast cell microscopy images with labels, in the format of `_im.tif`, `_mask.tif`;
2. Evaluation(Test) Dataset:
   5 new yeast microscopy images with labels, in the format of `_image.tif`, `_mask.tif`;

The Datasets were provided by Prof. Sahand Jamal Rahi and the Laboratory of the Physics of Biological Systems (LPBS). 
   
## Model: 
<img width="707" alt="image" src="https://github.com/CS-433/ml-project-2-cellsegmentors/assets/129077217/f0b11c48-eef0-4ea7-9138-7164ef40389a">
  
- Design paradigm: U-Net  
- Encoder: adopted from SegFormer  
- Decoder: adopted from MA-Net  
- Heads: predicting cell probability and gradient flow map  
- Ensemble Predictor: combined with the pre-trained model and our fine-tuned model MEDIAR_YeastZ

- Pretrained model: The main_model of [MEDIAR-Former](https://github.com/Lee-Gihun/MEDIAR), the "1st winner" in the [NeurIPS-2022 Cell Segmentation Challenge](https://neurips22-cellseg.grand-challenge.org/)  

## Environment Setup:
**Table 1:** Environment Requirements
| Dependencies               | Setting                     |
| -------------------------- | ---------------------------- |
| Platform                   | Google Colab                |
| GPU                        | NVIDIA A100-SXM4-40GB       |
| CUDA version               | 11.8                         |
| Programming language       | Python v3.10.12             |
| Deep learning framework    | [Pytorch v2.1.0 (torchvision v0.16.1)](https://pytorch.org/vision/stable/index.html) |
|    Package dependencies    | [MONAI (v0.9.0)](https://docs.monai.io/en/stable/)                      |
|                            | [Segmentation Models Pytorch (v0.3.3)](https://smp.readthedocs.io/en/latest/) |
|                            | [Timm (v0.9.2)](https://huggingface.co/timm)                |
|                            | [Pretrained models (v0.7.4)](https://deepspeech.readthedocs.io/en/v0.7.4/)   |



## Training:
<img width="900" alt="image" src="https://github.com/CS-433/ml-project-2-cellsegmentors/assets/129077217/aa8bfefe-a7fa-44cf-81e0-a90fcabbd0ce">

**Table 2:** Hyperparameters and Training Information
| Hyperparameters           | Setting                                   |
| ------------------------- | ----------------------------------------- |
| Pretrained model          | MEDIAR(main_model)                        |
| Batch size                | 8                                         |
| Training epochs           | 60                                        |
| Optimizer                 | AdamW                                     |
| Initial Lr                | 5e-5                                      |
| Lr decay scheduler        | Cosine ($T_i$ = 100, $\eta_{min}$ = 1e-7, no restart) |
|                           |                                           |
|                **Training Overview**                                  |
| Training time             | 3.5 hours                                |
| Average memory usage      | 19.5 GB                                 |
| Final train loss          | 0.1417                                  |
| Final Validation loss     | 0.1836                                  |
| Final Validation F1 score  | 0.9791                                  |
| Final AP score*           | 0.9776                                  |

*Tested on 808 images of the training dataset

The mapping file linking images and labels is generated by:
```python
python ./generate_mapping.py --root=<path_to_data>
```

To train the model, run the following command:

```python
python ./main.py --config_path=<path_to_config>
```
**Configurations**:  
`baseline.json`: train the Swin-UNetr model as the baseline  
`Mediar_train`: train the MEDIAR model

## Inference:
<img width="917" alt="image" src="https://github.com/CS-433/ml-project-2-cellsegmentors/assets/129077217/4db2be5e-3f60-420b-a313-8d9175d4654a">

To conduct prediction on the testing cases, run:

```python
python predict.py --config_path=<path_to_config>
```
**Configurations**:  
`base_prediction.json`: using the Swin-UNetr model  
`baseline_prediction.json`: using the pretrained MEDIAR model  
`Mediar_prediction.json`: using the trained MEDIAR_YeastZ model only  
`ensemble_tta.json`: using the ensemble model of pretrained MEDIAR and MEDIAR_YeastZ and stochastic test time augmentation(TTA).

Most of the images can be predicted within 1 sec.

## Evaluation: 
- Remove Boundary Cells: This helps in obtaining more accurate evaluation metrics by focusing on cells that are entirely contained within the image and avoids potential issues caused by partial cells at the edges.
- Intersection over Union (IoU): It measures the degree of overlap between predicted and ground truth regions. It is computed as the ratio of the intersection of the predicted and true regions to their union. IoU has a range of (0,1). High IoU values indicate accurate and precise segmentation, while lower values indicate a lack of overlap. 
- Measures: By comparing the IoU values between predicted and ground truth instances, a true positive is counted when the IoU is above the specified threshold(0.5), indicating a significant overlap. After getting the TP, FP, and FN in the confusion matrix,
  
**Precision**: TP/(TP + FP)

**Recall**: TP/(TP + FN)

**AP Score**: TP/(TP + FN + FP)

**F1 Score**: 2 * (Precision * Recall) / (Precision + Recall)

## Conclusion: 
MEDIAR_YeastZ is a robust segmentation model for yeast cells. It is less expensive in computing and more efficiently trained from the pretrained model MEDIAR main_model. Its generalization is tested on a new unseen dataset, and the accuracy is **0.9329**.
